{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50b73f5f-7b90-40c5-92d4-f3569bd9c146",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Load data from all sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c38af40-c0cb-4564-a210-3164dc8f28b9",
   "metadata": {},
   "source": [
    "#### Load name and path of all sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155729ab-ad2e-4fa4-a203-649520e7c883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "from pyscan.session_utils import find_all_sessions\n",
    "\n",
    "# Find all included sessions from Google sheet, with structure session_name: path\n",
    "session_dict = find_all_sessions(sheet_path = 'https://docs.google.com/spreadsheets/d/1_Xs5i-rHNTywV-WuQ8-TZliSjTxQCCqGWOD2AL_LIq0/edit#gid=0',\n",
    "                                 data_path = '/home/isabella/Documents/isabella/jake/recording_data',\n",
    "                                 sorting_suffix = 'sorting_ks2_custom')\n",
    "print(f'{len(session_dict.items())} sessions found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763bd5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87021594-d600-416a-9d37-7923efee2f4e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Loop over all sessions, load data and filter for pyramidal cells\n",
    "### Criteria:\n",
    "#### - A. Cluster marked 'good' in phy\n",
    "#### - B. Cluster depth 0 +-200um\n",
    "#### - C. Mean FR < 10 Hz\n",
    "#### - D. Mean spike width >500us\n",
    "#### - E. Burst index - first moment of AC < 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce5f843-a9a4-4eb1-8d0c-eba9cd178e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyscan.ephys import ephys\n",
    "from pyscan.postprocessing.burst_index_and_autocorrelograms import *\n",
    "\n",
    "total_cells_inc = 0\n",
    "total_cells_processed = 0\n",
    "\n",
    "cluster_info_all = pd.DataFrame()\n",
    "df_all_cells = pd.DataFrame(columns = ['clusters_inc', 'ephys_object'], dtype = 'object')\n",
    "\n",
    "for session, session_path in session_dict.items():\n",
    "    \n",
    "    # Create ephys object\n",
    "    obj = ephys(recording_type = 'nexus', path = session_path)\n",
    "    \n",
    "    ## A. Load good cells from phy\n",
    "    obj.load_spikes('good')\n",
    "    \n",
    "    # Get cluster info from phy\n",
    "    cluster_info = obj.spike_data['cluster_info']\n",
    "\n",
    "    cluster_info['session'] = session\n",
    "    \n",
    "    # Get total good cells for session\n",
    "    total_cells = len(cluster_info.index)\n",
    "    total_cells_processed += total_cells\n",
    "    \n",
    "    ## B. Get cluster depths and exclude any outside of 0 +-200um\n",
    "    cluster_info = cluster_info[cluster_info['depth'].between(-200, 200)].copy()\n",
    "\n",
    "    ## C. Filter for mean firing rate between 0-10 Hz\n",
    "    cluster_info = cluster_info[cluster_info['fr'].between(0, 10)]\n",
    "    \n",
    "    ## D. Filter for spike width >300 us from template\n",
    "    if not cluster_info.empty:\n",
    "        obj.load_mean_waveforms(clusters_to_load = list(cluster_info.index)) #Pick up to 500 spikes at random for performance\n",
    "\n",
    "        # Calculate spike width for each cluster from mean of every 50th spike \n",
    "        for cluster, mean_waveform in obj.mean_waveforms.items():\n",
    "            \n",
    "            # Find peak to trough time in us\n",
    "            peak = np.argmin(mean_waveform)\n",
    "            trough = np.argmax(mean_waveform[peak:]) + peak\n",
    "            peak_to_trough = trough - peak         \n",
    "\n",
    "            # # Plot for sanity\n",
    "            # print(f'Spike width for cluster {cluster}: {peak_to_trough / obj.spike_data[\"sampling_rate\"] * 1e6} us')\n",
    "            # plt.plot(mean_waveform)\n",
    "            # plt.scatter(trough, mean_waveform[trough])\n",
    "            # plt.scatter(peak, mean_waveform[peak])\n",
    "            # plt.show()\n",
    "\n",
    "            cluster_info.loc[cluster, 'spike_width_microseconds'] = (peak_to_trough / obj.spike_data['sampling_rate']) * 1e6\n",
    "        \n",
    "        # Filter for spike width > 300us as in Wills et al., 2010\n",
    "        cluster_info = cluster_info[cluster_info['spike_width_microseconds'] > 500].copy()\n",
    "\n",
    "    \n",
    "    ## E. Calculate burst index and filter\n",
    "    if not cluster_info.empty:\n",
    "        \n",
    "        # Reload spike data only for included cells\n",
    "        clusters_inc = list(cluster_info.index)\n",
    "        obj.load_spikes(clusters_to_load = clusters_inc)\n",
    "        \n",
    "        # Generate autocorrelograms and burst index for each cluster\n",
    "        spike_times_inc = obj.spike_data['spike_times']\n",
    "        spike_clusters_inc = obj.spike_data['spike_clusters']\n",
    "\n",
    "        autocorrelograms, first_moments = compute_autocorrelograms_and_first_moment(spike_times_inc, \n",
    "                                                                                     spike_clusters_inc, \n",
    "                                                                                     bin_size = 0.001, #1ms\n",
    "                                                                                     time_window = 0.05) #50ms\n",
    "        \n",
    "        cluster_info['first_moment_AC'] = first_moments.values()\n",
    "        \n",
    "        # Filter for first moment <25\n",
    "        cluster_info = cluster_info[cluster_info['first_moment_AC'] < 25]\n",
    "            \n",
    "    ## SAVE INCLUDED CLUSTER IDs TO .NPY\n",
    "    clusters_inc = cluster_info.index\n",
    "    n_clusters_inc = len(cluster_info.index)\n",
    "    total_cells_inc += n_clusters_inc\n",
    "\n",
    "    # Append session to cluster_info_all index\n",
    "    cluster_info.index = cluster_info['session'] + '_' + cluster_info.index.astype(str)\n",
    "    \n",
    "    # Concat cluster info for all sessions\n",
    "    cluster_info_all = pd.concat([cluster_info_all, cluster_info])\n",
    "\n",
    "    # Save included clusters to .npy\n",
    "    np.save(f'{session_path}/clusters_inc.npy', clusters_inc)\n",
    "\n",
    "    # Make df_all_cells\n",
    "    df_all_cells.loc[session, 'clusters_inc'] = clusters_inc.values\n",
    "    df_all_cells.loc[session, 'ephys_object'] = obj      \n",
    "        \n",
    "    print(f'Session {session}: {n_clusters_inc} cells retained of {total_cells} good cells from phy. Retained cells: {clusters_inc.values}')\n",
    "\n",
    "print(f'Total cells retained: {total_cells_inc} of total {total_cells_processed} good cells from phy')\n",
    "\n",
    "# Save cluster_info_all and df_all_cells to pickle\n",
    "pd.to_pickle(cluster_info_all, '/home/isabella/Documents/isabella/jake/ephys_analysis/processed_data/cluster_info_all.pkl')\n",
    "pd.to_pickle(df_all_cells, '/home/isabella/Documents/isabella/jake/ephys_analysis/processed_data/df_all_cells.pkl')\n",
    "print('cluster_info_all and df_all_cells saved to pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a3389d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd278f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(cluster_info_all['spike_width_microseconds'], cluster_info_all['fr'])\n",
    "plt.xlabel('Spike width (us)')\n",
    "# Set y axis to log 10 scale\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Firing rate')\n",
    "plt.title('Spike width vs firing rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f92bdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spatial info all\n",
    "spatial_info_all = pd.read_pickle('/home/isabella/Documents/isabella/jake/ephys_analysis/processed_data/spatial_info_all.pkl')\n",
    "\n",
    "# Select only rows including 'open-field_1'\n",
    "spatial_info_open_field_1 = spatial_info_all[spatial_info_all.index.str.contains('raw_open-field_1')]\n",
    "\n",
    "# Drop 'open-field_1' from index\n",
    "spatial_info_open_field_1.index = spatial_info_open_field_1.index.str.replace('raw_open-field_1_', '')\n",
    "\n",
    "\n",
    "spatial_info_open_field_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ab8ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge cluster_info_all with spatial_info_open_field_1\n",
    "cluster_info_spatial_info = pd.merge(cluster_info_all, spatial_info_open_field_1, left_index = True, right_index = True)\n",
    "\n",
    "# Plot spike width against bits per spike\n",
    "plt.scatter(cluster_info_spatial_info['spike_width_microseconds'], cluster_info_spatial_info['bits_per_spike'])\n",
    "plt.xlabel('Spike width (us)')\n",
    "plt.ylabel('Bits per spike')\n",
    "plt.title('Spike width vs bits per spike')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f156ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot firing rate against bits per spike\n",
    "plt.scatter(cluster_info_spatial_info['fr'], cluster_info_spatial_info['bits_per_spike'])\n",
    "plt.xlabel('Firing rate')\n",
    "plt.ylabel('Bits per spike')\n",
    "plt.title('Firing rate vs bits per spike')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669da078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot first moment of autocorrelogram against bits per spike\n",
    "plt.scatter(cluster_info_spatial_info['first_moment_AC'], cluster_info_spatial_info['bits_per_spike'])\n",
    "plt.xlabel('First moment of autocorrelogram')\n",
    "plt.ylabel('Bits per spike')\n",
    "plt.title('First moment of autocorrelogram vs bits per spike')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3571ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot spike width vs burst index\n",
    "plt.scatter(cluster_info_spatial_info['spike_width_microseconds'], cluster_info_spatial_info['first_moment_AC'])\n",
    "plt.xlabel('Spike width (us)')\n",
    "plt.ylabel('Burst index')\n",
    "plt.title('Spike width vs burst index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2847dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface.full as si\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.curation as sc\n",
    "import numpy as np\n",
    "\n",
    "from spikeinterface.postprocessing import compute_template_metrics, compute_spike_amplitudes\n",
    "\n",
    "recording_path = '/home/isabella/Documents/isabella/jake/recording_data/r1354/2023-05-06/230506_r1354_raw_open-field_1_preprocessed'\n",
    "\n",
    "recording = si.load_extractor(recording_path)\n",
    "recording\n",
    "\n",
    "sorting = se.read_phy('/home/isabella/Documents/isabella/jake/recording_data/r1354/2023-05-06/230506_sorting_ks2_custom', exclude_cluster_groups=['noise', 'mua'])\n",
    "sorting\n",
    "\n",
    "sorting = sc.remove_excess_spikes(sorting, recording)\n",
    "\n",
    "clusters_inc = np.load('/home/isabella/Documents/isabella/jake/recording_data/r1354/2023-05-06/clusters_inc.npy')\n",
    "\n",
    "\n",
    "waveform_extractor = si.extract_waveforms(recording=recording, \n",
    "                                          sorting=sorting, \n",
    "                                          folder = f'waveforms',\n",
    "                                          load_if_exists=True,\n",
    "                                          n_jobs = -1)\n",
    "\n",
    "\n",
    "template_metrics = compute_template_metrics(waveform_extractor)\n",
    "amplitudes = compute_spike_amplitudes(waveform_extractor, outputs = 'by_unit')\n",
    "display(template_metrics.loc[clusters_inc, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9718a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface.preprocessing as spre\n",
    "import spikeinterface.widgets as sw\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "\n",
    "recording_highpass = spre.highpass_filter(recording, freq_min=300)\n",
    "\n",
    "channel_dict = si.get_template_extremum_channel(waveform_extractor)\n",
    "good_units = {key: channel_dict[key] for key in channel_dict if key in clusters_inc}\n",
    "\n",
    "channels = list(good_units.values())\n",
    "unit_ids = list(good_units.keys())\n",
    "\n",
    "unit_index = 1\n",
    "\n",
    "def plot_data(start, time_window):\n",
    "    fig, ax = plt.subplots()\n",
    "    sw.plot_traces(recording_highpass, time_range=(start, start + time_window), channel_ids=[channels[unit_index]], show_channel_ids=True, ax=ax, color = 'blue')\n",
    "    sw.plot_rasters(sorting=sorting, segment_index=0, time_range=(start, start + time_window), unit_ids=[unit_ids[unit_index]], color='orange', ax=ax)\n",
    "    plt.show()\n",
    "\n",
    "# Define the time range for the widget\n",
    "total_time = recording_highpass.get_num_frames() / recording_highpass.get_sampling_frequency()\n",
    "time_window = 1  # Length of the time window in seconds\n",
    "\n",
    "# Create the widget\n",
    "widgets.interact(plot_data,\n",
    "                 start=widgets.FloatSlider(min=0, max=total_time-time_window, step=0.008, value=0, description='Start Time'),\n",
    "                 time_window=widgets.FloatSlider(min=0.001, max=time_window, step=0.0005, value=time_window, description='Time Window'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "env_38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
