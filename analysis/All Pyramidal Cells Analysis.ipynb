{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7705120-8596-455c-b10f-d6a21a94c0ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Load data for all pyramidal cells from all t-maze trials into a dataframe of ephys objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e2fd9d-c69e-43e1-9445-9d0e82f49b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "from session_utils import *\n",
    "from ephys import *\n",
    "from ephys_utils import select_spikes_by_trial\n",
    "\n",
    "lfp_sampling_rate = 1000\n",
    "\n",
    "# Load all session names and paths as dict\n",
    "session_list = find_all_sessions(sheet_path = 'https://docs.google.com/spreadsheets/d/1_Xs5i-rHNTywV-WuQ8-TZliSjTxQCCqGWOD2AL_LIq0/edit#gid=0',\n",
    "                                 data_path = '/home/isabella/Documents/isabella/jake/recording_data',\n",
    "                                 sorting_suffix = 'sorting_ks2_custom')\n",
    "\n",
    "# Initialise DataFrame and explicitly set dtype for 'clusters_inc' to 'object'\n",
    "df_all_cells = pd.DataFrame(data = None, index = session_list.keys(), columns=['clusters_inc'], dtype='object')\n",
    "\n",
    "\n",
    "for i, session_path in enumerate(session_list.values()):\n",
    "    session = list(session_list.keys())[i]\n",
    "    \n",
    "    # Get IDs of included clusters from postprocessing.Select Clusters All Sessions.ipynb\n",
    "    clusters_inc = np.load(f'{session_path}/clusters_inc.npy', allow_pickle = True)\n",
    "    \n",
    "    if len(clusters_inc) > 0:\n",
    "        df_all_cells.at[session, 'clusters_inc'] = clusters_inc\n",
    "\n",
    "        # Create ephys object for session and add to dataframe\n",
    "        obj = ephys(recording_type = 'nexus', path = session_path)\n",
    "        \n",
    "        # Find t-maze trials\n",
    "        t_maze_trials = [i for i, s in enumerate(obj.trial_list) if 't-maze' in s]\n",
    "\n",
    "        # Load spikes for all included clusters\n",
    "        obj.load_spikes(clusters_inc)\n",
    "        \n",
    "        # Select only t-maze spikes\n",
    "        obj.t_maze_spikes = select_spikes_by_trial(obj.spike_data, t_maze_trials, obj.trial_offsets)\n",
    "\n",
    "        # Load position data for t-maze trials\n",
    "        obj.load_pos(t_maze_trials, output_flag = False, reload_flag = False)\n",
    "\n",
    "        # Get unique channels with included cells\n",
    "        obj.good_channels = np.unique(obj.spike_data['cluster_info'].loc(axis=1)['ch'])\n",
    "        \n",
    "        # Load LFP for all t-maze trials for channels with units\n",
    "        obj.load_lfp(t_maze_trials, lfp_sampling_rate, channels = obj.good_channels, reload_flag = True)\n",
    "\n",
    "        # Add data to frame\n",
    "        df_all_cells.at[list(session_list.keys())[i], 'ephys_object'] = obj\n",
    "\n",
    "    print(f'Loaded session {session}')\n",
    "\n",
    "# Pickle dataframe for loading elsewhere\n",
    "df_all_cells.to_pickle('/home/isabella/Documents/isabella/jake/ephys_objects/df_all_cells.pkl')\n",
    "\n",
    "df_all_cells.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2a6e6e-5eb9-44b2-9c6a-a07d7e9ac850",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Calculate theta phase for all pyramidal cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d189f8-c41f-4416-8da2-25d81a0189b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "from position_analysis import *\n",
    "from get_theta_frequencies import get_theta_frequencies\n",
    "from get_theta_phase import get_theta_phase\n",
    "from ephys import *\n",
    "\n",
    "# Load pickled data\n",
    "df_all_cells = pd.read_pickle('/home/isabella/Documents/isabella/jake/ephys_analysis/ephys_objects/df_all_cells.pkl')\n",
    "\n",
    "lfp_sampling_rate = 1000\n",
    "\n",
    "# Drop rows with no included clusters\n",
    "df_all_cells = df_all_cells.dropna()\n",
    "print(f'{len(df_all_cells.index)} sessions retained')\n",
    "\n",
    "# Loop through all sessions\n",
    "for index, obj in df_all_cells['ephys_object'].iteritems():\n",
    "    \n",
    "    # Find t-maze trials for session\n",
    "    t_maze_trials = [i for i, s in enumerate(obj.trial_list) if 't-maze' in s]\n",
    "    \n",
    "    # Initialise output variables\n",
    "    obj.cluster_phases = {}\n",
    "    obj.cluster_sectors = {}\n",
    "\n",
    "    # Load LFP and position for each channel, get theta phase and position sector for each spike\n",
    "    for i in t_maze_trials:\n",
    "        \n",
    "        # Extract XY position data for trial\n",
    "        trial_pos = obj.pos_data[i]['xy_position']\n",
    "\n",
    "        # Convert to DataFrame and rename columns to match original channel\n",
    "        lfp_df = pd.DataFrame(obj.lfp_data[i]['data'])\n",
    "        lfp_df.columns = obj.good_channels\n",
    "\n",
    "        # Find peak theta frequencies for each channel and make dict of {channel: theta_freq}\n",
    "        theta_freqs = get_theta_frequencies(obj.lfp_data[i]['data'], lfp_sampling_rate)\n",
    "        theta_freqs = dict(zip(obj.good_channels, theta_freqs))\n",
    "\n",
    "\n",
    "        # Loop through each good cluster\n",
    "        for cluster in obj.spike_data['cluster_info'].index:\n",
    "            # Get channel for cluster\n",
    "            channel = obj.spike_data['cluster_info'].loc[cluster, 'ch']\n",
    "\n",
    "            # Get peak theta frequency\n",
    "            theta_freq = theta_freqs[channel]\n",
    "\n",
    "            ## SPIKE PHASE\n",
    "            # Extract LFP data for the recording channel\n",
    "            lfp_data_for_channel = lfp_df.loc[:, channel]\n",
    "\n",
    "            # Extract spike times for the cluster\n",
    "            cluster_spike_times = obj.t_maze_spikes[i]['spike_times'][obj.t_maze_spikes[i]['spike_clusters'] == cluster]\n",
    "\n",
    "            # Compute theta phases for the spike times\n",
    "            spike_phases = get_theta_phase(lfp_data_for_channel, cluster_spike_times, lfp_sampling_rate, theta_freq)\n",
    "\n",
    "            # Store in the dictionary\n",
    "            obj.cluster_phases[cluster] = spike_phases    \n",
    "\n",
    "            ## SPIKE POSITION SECTOR\n",
    "            # Assign spike times to nearest position sector\n",
    "            spike_pos = [[], []]\n",
    "            for t in cluster_spike_times:\n",
    "                spike_pos_index = round(t * 50)/50\n",
    "                spike_pos[0].append(trial_pos[spike_pos_index].values[0])\n",
    "                spike_pos[1].append(trial_pos[spike_pos_index].values[1])\n",
    "\n",
    "            # spike_pos is now an array with the structure  [[x1, x2, x3 ...], [y1, y2, y3 ...]] for each spike\n",
    "            # Get position sector for each spike\n",
    "            spike_sectors = assign_sectors(pd.DataFrame(spike_pos))\n",
    "\n",
    "            # add sectors to dict\n",
    "            obj.cluster_sectors[cluster] = spike_sectors\n",
    "    \n",
    "    # Re-assign object to dataframe\n",
    "    df_all_cells.loc[index, 'ephys_object'] = obj\n",
    "    print(f'Session {index} processed')\n",
    "\n",
    "# Pickle dataframe for loading elsewhere\n",
    "df_all_cells.to_pickle('/home/isabella/Documents/isabella/jake/ephys_analysis/ephys_objects/df_all_cells.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2378d3ba-86e3-4076-ac68-8d39803867eb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Plot theta phase vs position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34260dfe-bb60-45a8-85ac-57fd61a441a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting functions\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "\n",
    "# Function to get phases for a given sector within a specific cluster\n",
    "def get_phases_for_sector_in_cluster(cluster_sectors, cluster_phases, sector, cluster_id):\n",
    "    indices = np.where(cluster_sectors[int(cluster_id)] == sector)[0]\n",
    "    return cluster_phases[int(cluster_id)][indices]\n",
    "\n",
    "# Function to plot polar plots for a specific cluster\n",
    "def plot_theta_phase_by_position_cluster(obj, cluster_id, session):\n",
    "    \n",
    "    # Define the directory where you want to save the figure\n",
    "    save_directory = f'/home/isabella/Documents/isabella/jake/ephys_analysis/figures/P{obj.age}_{session}'\n",
    "    \n",
    "    # Check if the directory exists, if not, create it\n",
    "    if not os.path.exists(save_directory):\n",
    "        os.makedirs(save_directory)\n",
    "        \n",
    "    \n",
    "    unique_sectors = range(1,13)\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(15, 10), subplot_kw={'projection': 'polar'})\n",
    "    \n",
    "    for idx, sector in enumerate(unique_sectors):\n",
    "        row_idx = idx // 4\n",
    "        col_idx = idx % 4\n",
    "        sector = int(sector)\n",
    "        \n",
    "        phases = get_phases_for_sector_in_cluster(obj.cluster_sectors, obj.cluster_phases, sector, cluster_id)\n",
    "        \n",
    "        # Remove any NaN/ infinite values\n",
    "        phases = phases[np.isfinite(phases)]\n",
    "        \n",
    "        # Calculate circular mean of theta phase\n",
    "        mean_phase = scipy.stats.circmean(phases, nan_policy = 'omit')\n",
    "        std_phase = scipy.stats.circstd(phases, nan_policy = 'omit')\n",
    "        \n",
    "        # Histogram of the phases\n",
    "        n, bins, patches = axes[row_idx, col_idx].hist(phases, bins=30, alpha=0.6)\n",
    "        \n",
    "        # Add a red line indicating the mean phase\n",
    "        axes[row_idx, col_idx].axvline(mean_phase, color='r', linestyle='--', linewidth=2)\n",
    "        \n",
    "        # Add a sector indicating standard deviation\n",
    "        # axes[row_idx, col_idx].axvspan(mean_phase-std_phase, mean_phase+std_phase, color='r', alpha = 0.4)\n",
    "        \n",
    "        # Set the title for the current subplot\n",
    "        axes[row_idx, col_idx].set_title(f\"Sector {sector}\")\n",
    "\n",
    "    plt.suptitle(f'Theta phase vs position sector for cluster {cluster_id} from session {session}', fontsize = 25)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_directory}/{cluster_id}_theta_phase_by_sector.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504edb6f-b2b3-4168-be54-a983eef70497",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot theta phase vs position\n",
    "\n",
    "# Loop through all sessions and make all plots per cluster\n",
    "for session, obj in df_all_cells['ephys_object'].iteritems():\n",
    "    \n",
    "    # Loop through each good cluster\n",
    "    for cluster in obj.spike_data['cluster_info'].index:\n",
    "        \n",
    "        plot_theta_phase_by_position_cluster(obj, cluster, session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac944b4a-544b-46a9-ae2d-c1a8e547065e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Plot rate maps for pyramidal cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a3656a-ac41-4963-b6e7-ed94d80a0a22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "from postprocessing.spatial_analysis import make_rate_maps, plot_cluster_across_sessions\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ephys_utils import select_spikes_by_trial, transform_spike_data\n",
    "\n",
    "\n",
    "# Load pickled data\n",
    "df_all_cells = pd.read_pickle('/home/isabella/Documents/isabella/jake/ephys_analysis/ephys_objects/df_all_cells.pkl')\n",
    "# Drop rows with no included clusters\n",
    "df_all_cells = df_all_cells.dropna()\n",
    "print(f'{len(df_all_cells.index)} sessions retained')\n",
    "\n",
    "\n",
    "# Plot rate maps\n",
    "for session, obj in df_all_cells['ephys_object'].iteritems():\n",
    "    \n",
    "    # Loop through trials and generate rate maps\n",
    "    rate_maps = {}\n",
    "    occupancy = {}\n",
    "    \n",
    "    # Make rate maps for all trials\n",
    "    for trial, trial_name in enumerate(obj.trial_list):\n",
    "        \n",
    "        # Load unloaded (open field) position data\n",
    "        obj.load_pos(trial)\n",
    "\n",
    "        # Select spikes for current trial and transform to create a dict of {cluster: spike_times, cluster:spike_times}\n",
    "        current_trial_spikes = select_spikes_by_trial(obj.spike_data, trial, obj.trial_offsets)\n",
    "        current_trial_spikes = transform_spike_data(current_trial_spikes)\n",
    "\n",
    "\n",
    "        rate_maps[trial], occupancy[trial] = make_rate_maps(spike_data = current_trial_spikes,\n",
    "                                   positions = obj.pos_data[trial]['xy_position'],  \n",
    "                                   ppm = 400, \n",
    "                                   x_bins = 50,\n",
    "                                   y_bins = 50,\n",
    "                                   dt = 1.0,\n",
    "                                   smoothing_window = 10)\n",
    "    \n",
    "    # # Save rate maps to dataframe\n",
    "    # df_all_cells.loc[session, 'rate_maps'] = rate_maps\n",
    "    # df_all_cells.loc[session, 'occupancy'] = occupancy\n",
    "    \n",
    "    # Define the directory where you want to save the figures\n",
    "    save_directory = f'/home/isabella/Documents/isabella/jake/ephys_analysis/figures/P{obj.age}_{session}'\n",
    "    \n",
    "    # Check if the directory exists, if not, create it\n",
    "    if not os.path.exists(save_directory):\n",
    "        os.makedirs(save_directory)\n",
    "    \n",
    "    for cluster in obj.spike_data['cluster_info'].index:\n",
    "        plot_cluster_across_sessions(rate_maps, cluster, session = session)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{save_directory}/{cluster}_rate_maps.png')\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff048a1f-701f-459d-ae67-922b17e55d86",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Plot autocorrelograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72e0c40-486d-4bb0-abc9-217a61880fe0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from postprocessing.burst_index_and_autocorrelograms import compute_autocorrelograms_and_burst_indices, plot_autocorrelogram\n",
    "\n",
    "# Loop through all sessions and make all plots per cluster\n",
    "for session, obj in df_all_cells['ephys_object'].iteritems():\n",
    "    \n",
    "    save_directory = f'/home/isabella/Documents/isabella/jake/ephys_analysis/figures/P{obj.age}_{session}'\n",
    "    \n",
    "    # Load spikes for all good clusters\n",
    "    \n",
    "    autocorrelograms, burst_indices = compute_autocorrelograms_and_burst_indices(\n",
    "        spike_times = obj.spike_data['spike_times'],\n",
    "        spike_clusters = obj.spike_data['spike_clusters'],\n",
    "        bin_size = 0.001, #1ms\n",
    "        time_window = 0.05, #50ms\n",
    "        burst_threshold = 0.01) #10 ms\n",
    "    \n",
    "    # Loop through each good cluster and plot autocorrelogram, labelled with burst index\n",
    "    for cluster, autocorrelogram in autocorrelograms.items():\n",
    "        fig, ax = plot_autocorrelogram(session, cluster, autocorrelogram, burst_indices[cluster])\n",
    "        plt.savefig(f'{save_directory}/{cluster}_autocorrelogram.png')\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286ea11b-aa70-4253-8bf7-8d2c18528206",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Combine all plots for a single cluster into one image for checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e9fde4-2312-4978-96b8-0d76dc58559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def combine_images_vertically(image_list):\n",
    "    \"\"\"\n",
    "    Combine a list of images vertically.\n",
    "    \n",
    "    Parameters:\n",
    "        image_list (list): List of Image objects to combine.\n",
    "        \n",
    "    Returns:\n",
    "        Image: Combined image.\n",
    "    \"\"\"\n",
    "    images = [Image.open(i) for i in image_list]\n",
    "    widths, heights = zip(*(i.size for i in images))\n",
    "    \n",
    "    total_height = sum(heights)\n",
    "    max_width = max(widths)\n",
    "    \n",
    "    new_img = Image.new('RGB', (max_width, total_height))\n",
    "    \n",
    "    y_offset = 0\n",
    "    for img in images:\n",
    "        new_img.paste(img, (0, y_offset))\n",
    "        y_offset += img.height\n",
    "    \n",
    "    return new_img\n",
    "\n",
    "def clear_combined_images(subdir):\n",
    "    \"\"\"\n",
    "    Remove previously combined images in a given subdirectory.\n",
    "    \n",
    "    Parameters:\n",
    "        subdir (str): The path to the subdirectory.\n",
    "    \"\"\"\n",
    "    for file in os.listdir(subdir):\n",
    "        if file.endswith('_combined.png'):\n",
    "            os.remove(os.path.join(subdir, file))\n",
    "\n",
    "def process_directory(main_directory):\n",
    "    \"\"\"\n",
    "    Process the main directory to combine .png files with the same prefix within each subfolder.\n",
    "    \n",
    "    Parameters:\n",
    "        main_directory (str): The path to the main directory containing subfolders.\n",
    "    \"\"\"\n",
    "    total_clusters = 0\n",
    "    \n",
    "    for subdir, _, files in os.walk(main_directory):\n",
    "        clear_combined_images(subdir)\n",
    "        \n",
    "        prefix_to_files = {}\n",
    "        \n",
    "        for file in files:\n",
    "            if file.endswith('.png') and not file.endswith('_combined.png'):\n",
    "                prefix = file[:3]\n",
    "                if prefix not in prefix_to_files:\n",
    "                    prefix_to_files[prefix] = []\n",
    "                prefix_to_files[prefix].append(os.path.join(subdir, file))\n",
    "                \n",
    "        for prefix, file_paths in prefix_to_files.items():\n",
    "            if len(file_paths) > 1:\n",
    "                combined_img = combine_images_vertically(file_paths)\n",
    "                combined_img_path = os.path.join(subdir, f\"{prefix}_combined.png\")\n",
    "                combined_img.save(combined_img_path)\n",
    "        total_clusters += 1\n",
    "                \n",
    "    return(total_clusters)\n",
    "\n",
    "# Process all figures\n",
    "total_cluster = process_directory('/home/isabella/Documents/isabella/jake/ephys_analysis/figures')\n",
    "total_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84accc3f-ff1d-477a-a9e0-0266ee2e78d9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Copy all combined images to a new directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7403455e-eb54-4498-b00c-109a26a5b46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def copy_png_files(source_directory, target_directory, substring):\n",
    "    \"\"\"\n",
    "    Traverse through a directory and its subdirectories to find all .png files containing a specific substring.\n",
    "    Then copy these files to a target directory.\n",
    "\n",
    "    Parameters:\n",
    "    - source_directory (str): The directory path to start the traversal.\n",
    "    - target_directory (str): The directory where the files will be copied to.\n",
    "    - substring (str): The substring that the .png file names should contain.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure that the target directory exists; if not, create it.\n",
    "    if not os.path.exists(target_directory):\n",
    "        os.makedirs(target_directory)\n",
    "\n",
    "    # Traverse through the source directory and its subdirectories.\n",
    "    for dirpath, _, filenames in os.walk(source_directory):\n",
    "        for filename in filenames:\n",
    "            # Check if the file is a .png and contains the specific substring.\n",
    "            if filename.endswith('.png') and substring in filename:\n",
    "                source_file_path = os.path.join(dirpath, filename)\n",
    "                target_file_path = os.path.join(target_directory, filename)\n",
    "\n",
    "                # Copy the file to the target directory.\n",
    "                shutil.copy2(source_file_path, target_file_path)\n",
    "                print(f\"Copied {filename} to {target_directory}\")\n",
    "\n",
    "copy_png_files(source_directory = '/home/isabella/Documents/isabella/jake/ephys_analysis/figures', target_directory = '/home/isabella/Documents/isabella/jake/ephys_analysis/all_cells_combined_figures', substring = 'combined')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_37",
   "language": "python",
   "name": "env_37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
