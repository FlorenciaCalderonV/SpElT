{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/isabella/Documents/isabella/jake/recording_data/r1503/2024-03-15/240315_r1503_open-field_1\n",
      "Sorting ConcatenateSegmentRecording: 384 channels - 30.0kHz - 1 segments - 18,613,123 samples \n",
      "                             620.44s (10.34 minutes) - int16 dtype - 13.31 GiB\n",
      "========================================\n",
      "Loading recording with SpikeInterface...\n",
      "number of samples: 18613123\n",
      "number of channels: 384\n",
      "numbef of segments: 1\n",
      "sampling rate: 30000.0\n",
      "dtype: int16\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/isabella/jake/ephys_analysis/Kilosort/kilosort/io.py:498: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  X[:, self.nt : self.nt+nsamp] = torch.from_numpy(data).to(self.device).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing filters computed in  1.37s; total  1.37s\n",
      "\n",
      "computing drift\n",
      "Re-computing universal templates from data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 311/311 [03:37<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift computed in  220.70s; total  222.06s\n",
      "\n",
      "Extracting spikes using templates\n",
      "Re-computing universal templates from data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 311/311 [03:40<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492135 spikes extracted in  223.48s; total  445.55s\n",
      "\n",
      "First clustering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [00:32<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436 clusters found, in  32.80s; total  478.35s\n",
      "\n",
      "Extracting spikes using cluster waveforms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 311/311 [01:18<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1017214 spikes extracted in  78.95s; total  557.30s\n",
      "\n",
      "Final clustering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [00:40<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375 clusters found, in  40.38s; total  597.69s\n",
      "\n",
      "Merging clusters\n",
      "350 units found, in  1.62s; total  599.30s\n",
      "\n",
      "Saving to phy and computing refractory periods\n",
      "170 units found with good refractory periods\n",
      "\n",
      "Total runtime: 600.60s = 00:10:0 h:m:s\n",
      "kilosort4 run time 600.98s\n",
      "Recording sorted!\n",
      " KS4 found 350 units\n",
      "\n",
      "Sorting saved to /home/isabella/Documents/isabella/jake/recording_data/r1503/2024-03-15/240315_sorting_ks4/sort\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/isabella/jake/ephys_analysis/spikeinterface/src/spikeinterface/core/basesorting.py:239: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spikeinterface as si\n",
    "import spikeinterface.extractors as se\n",
    "from pyscan.session_utils import gs_to_df\n",
    "from pyscan.preprocessing.np2_preprocessing import sort_np2\n",
    "\n",
    "# Required spreadsheet columns:\n",
    "# trial_name: name of the trial\n",
    "# path: path to the trial\n",
    "# probe_type: type of probe used\n",
    "# num_channels: number of channels\n",
    "# Include: 'Y' if the trial should be included in the sorting\n",
    "\n",
    "\n",
    "# Load sheet\n",
    "sheet = gs_to_df('https://docs.google.com/spreadsheets/d/1_Xs5i-rHNTywV-WuQ8-TZliSjTxQCCqGWOD2AL_LIq0/edit#gid=0')\n",
    "path_to_data = '/home/isabella/Documents/isabella/jake/recording_data/'\n",
    "sorting_suffix = 'sorting_ks4'\n",
    "sheet['path'] = path_to_data + sheet['path']\n",
    "\n",
    "# Select only NP2 data to be sorted\n",
    "sheet_inc = sheet[sheet['Include'] == 'Y']\n",
    "sheet_inc = sheet_inc[sheet_inc['probe_type'] == 'NP2_openephys']\n",
    "\n",
    "trial_list = sheet_inc['trial_name'].to_list()\n",
    "session_list = np.unique([f\"{i.split('_')[0]}_{i.split('_')[1]}\" for i in trial_list])\n",
    "recording_list = [[] for _ in range(len(session_list))]\n",
    "\n",
    "# Collect recordings into sessions and preprocess\n",
    "for i, session in enumerate(session_list):\n",
    "    for trial in trial_list:\n",
    "        if session in trial:\n",
    "            base_folder = sheet_inc[sheet_inc['trial_name'] == trial]['path'].tolist()[0]\n",
    "            num_channels = int(sheet_inc[sheet_inc['trial_name'] == trial]['num_channels'].tolist()[0])\n",
    "            electrode_type = sheet_inc[sheet_inc['trial_name'] == trial]['probe_type'].tolist()[0]\n",
    "            print(f\"{base_folder}/{trial}\")\n",
    "            recording = se.read_openephys(folder_path=f\"{base_folder}/{trial}\", stream_id = '0')\n",
    "            recording_list[i].append([recording,\n",
    "                                     trial, \n",
    "                                     base_folder, \n",
    "                                     electrode_type])\n",
    "\n",
    "# Concatenate over a single session and sort\n",
    "for recording in recording_list:\n",
    "    session = pd.DataFrame(recording)\n",
    "    recordings_concat = si.concatenate_recordings(session.iloc[:,0].to_list())\n",
    "    print(f'Sorting {recordings_concat}')\n",
    "    \n",
    "    sorting = sort_np2(recording = recordings_concat, \n",
    "\t\t\trecording_name = session.iloc[0,1], \n",
    "\t\t\tbase_folder = session.iloc[0,2],\n",
    "\t\t\tsorting_suffix = sorting_suffix)\n",
    "    session.to_csv(f'{session.iloc[0,2]}/{session.iloc[0,1][:6]}_{sorting_suffix}/session.csv') #save session trial info to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Loading recording with SpikeInterface...\n",
      "number of samples: 18613123\n",
      "number of channels: 384\n",
      "numbef of segments: 1\n",
      "sampling rate: 30000.0\n",
      "dtype: int16\n",
      "========================================\n",
      "Interpreting binary file as default dtype='int16'. If data was saved in a different format, specify `data_dtype`.\n",
      "Using GPU for PyTorch computations. Specify `device` to change this.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m settings \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfs\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m30000\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_chan_bin\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m384\u001b[39m}\n\u001b[1;32m      5\u001b[0m wrapper \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mRecordingExtractorAsArray(recordings_concat)\n\u001b[0;32m----> 6\u001b[0m ops, st, clu, tF, Wall, similar_templates, is_ref, est_contam_rate \u001b[38;5;241m=\u001b[39m \u001b[43mrun_kilosort\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNP2_kilosortChanMap.mat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/isabella/Documents/isabella/jake/recording_data/r1503/2024-03-15/240315_sorting_ks4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrapper\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/isabella/jake/ephys_analysis/Kilosort/kilosort/run_kilosort.py:127\u001b[0m, in \u001b[0;36mrun_kilosort\u001b[0;34m(settings, probe, probe_name, filename, data_dir, file_object, results_dir, data_dtype, do_CAR, invert_sign, device, progress_bar, save_extra_vars)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# NOTE: Also modifies settings in-place\u001b[39;00m\n\u001b[1;32m    125\u001b[0m filename, data_dir, results_dir, probe \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    126\u001b[0m     set_files(settings, filename, probe, probe_name, data_dir, results_dir)\n\u001b[0;32m--> 127\u001b[0m ops \u001b[38;5;241m=\u001b[39m \u001b[43minitialize_ops\u001b[49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_CAR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minvert_sign\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# Set preprocessing and drift correction parameters\u001b[39;00m\n\u001b[1;32m    130\u001b[0m ops \u001b[38;5;241m=\u001b[39m compute_preprocessing(ops, device, tic0\u001b[38;5;241m=\u001b[39mtic0, file_object\u001b[38;5;241m=\u001b[39mfile_object)\n",
      "File \u001b[0;32m/data/isabella/jake/ephys_analysis/Kilosort/kilosort/run_kilosort.py:213\u001b[0m, in \u001b[0;36minitialize_ops\u001b[0;34m(settings, probe, data_dtype, do_CAR, invert_sign, device)\u001b[0m\n\u001b[1;32m    211\u001b[0m ops[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvert_sign\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m invert_sign\n\u001b[1;32m    212\u001b[0m ops[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNTbuff\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ops[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m ops[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnt\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 213\u001b[0m ops[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNchan\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mprobe\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchanMap\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    214\u001b[0m ops[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_chan_bin\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m settings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_chan_bin\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    215\u001b[0m ops[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch_device\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(device)\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "import spikeinterface as si\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.widgets as sw\n",
    "\n",
    "recording_path = '/data/isabella/jake/recording_data/NP2 data/2024-03-15/test/2024-03-15_13-05-49'\n",
    "sorting_path = '/data/isabella/jake/recording_data/NP2 data/2024-03-15/test/kilosort4'\n",
    "\n",
    "recording = se.read_openephys(folder_path=recording_path, stream_id = '0')\n",
    "sorting = se.read_phy(sorting_path, exclude_cluster_groups=['noise', 'mua'])\n",
    "\n",
    "\n",
    "import spikeinterface.postprocessing as sp\n",
    "sorting_analyzer = si.create_sorting_analyzer(sorting=sorting, recording=recording)\n",
    "sorting_analyzer.compute('random_spikes')\n",
    "sorting_analyzer.compute('waveforms')\n",
    "sorting_analyzer.compute_one_extension('templates')\n",
    "si.postprocessing.compute_template_metrics(sorting_analyzer)\n",
    "unit_locations = sorting_analyzer.compute(input=\"unit_locations\", method=\"monopolar_triangulation\")\n",
    "\n",
    "sw.plot_rasters(sorting, time_range=[0, 10])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
