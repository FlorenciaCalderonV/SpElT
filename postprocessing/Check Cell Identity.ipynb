{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50b73f5f-7b90-40c5-92d4-f3569bd9c146",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Load data from all sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c38af40-c0cb-4564-a210-3164dc8f28b9",
   "metadata": {},
   "source": [
    "#### Load name and path of all sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "155729ab-ad2e-4fa4-a203-649520e7c883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 sessions found\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "from session_utils import find_all_sessions\n",
    "\n",
    "# Find all included sessions from Google sheet, with structure session_name: path\n",
    "session_dict = find_all_sessions(sheet_path = 'https://docs.google.com/spreadsheets/d/1_Xs5i-rHNTywV-WuQ8-TZliSjTxQCCqGWOD2AL_LIq0/edit#gid=0',\n",
    "                                 data_path = '/home/isabella/Documents/isabella/jake/recording_data',\n",
    "                                 sorting_suffix = 'sorting_ks2_custom')\n",
    "print(f'{len(session_dict.items())} sessions found')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87021594-d600-416a-9d37-7923efee2f4e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Loop over all sessions, load data and filter for pyramidal cells\n",
    "### Criteria:\n",
    "#### - A. Cluster marked 'good' in phy\n",
    "#### - B. Cluster depth 0 +-200um\n",
    "#### - C. Mean FR < 10 Hz\n",
    "#### - D. Mean spike width >300us\n",
    "#### - E. Burst index - first moment of AC < 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fce5f843-a9a4-4eb1-8d0c-eba9cd178e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-583.33333333]\n",
      "Session 230503_r1354: 0 cells retained of 5 good cells from phy. Retained cells: []\n",
      "[-458.33333333]\n",
      "[-500.]\n",
      "[-458.33333333]\n",
      "Session 230504_r1354: 0 cells retained of 8 good cells from phy. Retained cells: []\n",
      "Session 230505_r1354: 0 cells retained of 4 good cells from phy. Retained cells: []\n",
      "-541.6666666666666\n",
      "-562.5\n",
      "[-500.]\n",
      "[-520.83333333]\n",
      "[-270.83333333]\n",
      "[-145.83333333]\n",
      "[-166.66666667]\n",
      "[-208.33333333]\n",
      "[-375.]\n",
      "[-520.83333333]\n",
      "[-250.]\n",
      "[-41.66666667]\n",
      "[-83.33333333]\n",
      "[-83.33333333]\n",
      "[-104.16666667]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must have equal len keys and value when setting with an iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 41\u001b[0m\n\u001b[1;32m     37\u001b[0m         trough \u001b[38;5;241m=\u001b[39m trough[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     39\u001b[0m     peak_to_trough \u001b[38;5;241m=\u001b[39m trough \u001b[38;5;241m-\u001b[39m peak\n\u001b[0;32m---> 41\u001b[0m     \u001b[43mcluster_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcluster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspike_width_microseconds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m (peak_to_trough \u001b[38;5;241m/\u001b[39m obj\u001b[38;5;241m.\u001b[39mspike_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msampling_rate\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1e6\u001b[39m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m((peak_to_trough \u001b[38;5;241m/\u001b[39m obj\u001b[38;5;241m.\u001b[39mspike_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msampling_rate\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1e6\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Filter for spike width > 300us as in Wills et al., 2010\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/env_38/lib/python3.8/site-packages/pandas/core/indexing.py:849\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    848\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[0;32m--> 849\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/env_38/lib/python3.8/site-packages/pandas/core/indexing.py:1835\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1832\u001b[0m \u001b[38;5;66;03m# align and set the values\u001b[39;00m\n\u001b[1;32m   1833\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m take_split_path:\n\u001b[1;32m   1834\u001b[0m     \u001b[38;5;66;03m# We have to operate column-wise\u001b[39;00m\n\u001b[0;32m-> 1835\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_split_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1836\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1837\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[0;32m~/anaconda3/envs/env_38/lib/python3.8/site-packages/pandas/core/indexing.py:1891\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1886\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_integer(info_axis):\n\u001b[1;32m   1887\u001b[0m         \u001b[38;5;66;03m# This is a case like df.iloc[:3, [1]] = [0]\u001b[39;00m\n\u001b[1;32m   1888\u001b[0m         \u001b[38;5;66;03m#  where we treat as df.iloc[:3, 1] = 0\u001b[39;00m\n\u001b[1;32m   1889\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_with_indexer((pi, info_axis[\u001b[38;5;241m0\u001b[39m]), value[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 1891\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1892\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust have equal len keys and value \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1893\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen setting with an iterable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1894\u001b[0m     )\n\u001b[1;32m   1896\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lplane_indexer \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m   1897\u001b[0m     \u001b[38;5;66;03m# We get here in one case via .loc with a all-False mask\u001b[39;00m\n\u001b[1;32m   1898\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Must have equal len keys and value when setting with an iterable"
     ]
    }
   ],
   "source": [
    "from ephys import *\n",
    "from scipy.signal import argrelmax\n",
    "\n",
    "for session, session_path in session_dict.items():\n",
    "    \n",
    "    # Create ephys object\n",
    "    obj = ephys(recording_type = 'nexus', path = session_path)\n",
    "    \n",
    "    ## A. Load good cells from phy\n",
    "    obj.load_spikes('good')\n",
    "    \n",
    "    # Get cluster info from phy\n",
    "    cluster_info = obj.spike_data['cluster_info']\n",
    "    # Get total good cells for session\n",
    "    total_cells = len(cluster_info.index)\n",
    "    \n",
    "    \n",
    "    ## B. Get cluster depths and exclude any outside of 0 +-200um\n",
    "    cluster_info = cluster_info[cluster_info['depth'].between(-200, 200)].copy()\n",
    "    \n",
    "\n",
    "    ## C. Filter for mean firing rate between 0-10 Hz\n",
    "    cluster_info = cluster_info[cluster_info['fr'].between(0, 10)]\n",
    "    \n",
    "    ## D. Filter for spike width >300 us from template\n",
    "    if not cluster_info.empty:\n",
    "        obj.load_mean_waveforms(clusters_to_load = list(cluster_info.index)) #Pick up to 500 spikes at random for performance\n",
    "\n",
    "        # Calculate spike width for each cluster from mean of every 50th spike \n",
    "        for cluster, mean_waveform in obj.mean_waveforms.items():\n",
    "            \n",
    "            # Find peak to trough time in us\n",
    "            peak = np.argmin(mean_waveform)\n",
    "\n",
    "            trough = argrelmax(mean_waveform[peak:])[0] #Next local maxmimum after (negative) peak\n",
    "            if len(trough) > 1:\n",
    "                trough = trough[0]\n",
    "\n",
    "            peak_to_trough = trough - peak\n",
    "            \n",
    "            cluster_info.loc[cluster, 'spike_width_microseconds'] = (peak_to_trough / obj.spike_data['sampling_rate']) * 1e6\n",
    "        \n",
    "        # Filter for spike width > 300us as in Wills et al., 2010\n",
    "        cluster_info = cluster_info[cluster_info['spike_width_microseconds'] > 300].copy()\n",
    "\n",
    "    \n",
    "    ## E. Calculate burst index and filter\n",
    "    if not cluster_info.empty:\n",
    "        \n",
    "        # Reload spike data only for included cells\n",
    "        clusters_inc = list(cluster_info.index)\n",
    "        obj.load_spikes(clusters_to_load = clusters_inc)\n",
    "        \n",
    "        # Generate autocorrelograms and burst index for each cluster\n",
    "        from burst_index_and_autocorrelograms import *\n",
    "\n",
    "        spike_times_inc = obj.spike_data['spike_times']\n",
    "        spike_clusters_inc = obj.spike_data['spike_clusters']\n",
    "\n",
    "        autocorrelograms, first_moments = compute_autocorrelograms_and_first_moment(spike_times_inc, \n",
    "                                                                                     spike_clusters_inc, \n",
    "                                                                                     bin_size = 0.001, #1ms\n",
    "                                                                                     time_window = 0.05) #50ms\n",
    "        \n",
    "        cluster_info['first_moment_AC'] = first_moments.values()\n",
    "        \n",
    "        # Filter for first moment <25\n",
    "        cluster_info = cluster_info[cluster_info['first_moment_AC'] < 25]\n",
    "            \n",
    "    ## SAVE INCLUDED CLUSTER IDs TO .NPY\n",
    "    clusters_inc = cluster_info.index\n",
    "    n_clusters_inc = len(cluster_info.index)\n",
    "\n",
    "    np.save(f'{session_path}/clusters_inc.npy', clusters_inc)        \n",
    "        \n",
    "    print(f'Session {session}: {n_clusters_inc} cells retained of {total_cells} good cells from phy. Retained cells: {clusters_inc.values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edd278f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cluster_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcluster_info\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cluster_info' is not defined"
     ]
    }
   ],
   "source": [
    "cluster_info\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
