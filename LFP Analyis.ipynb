{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2f53d71-77ad-4125-b519-d9ca5a611e91",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from spelt.ephys import ephys\n",
    "from spelt.session_utils import find_all_sessions, make_df_all_sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df42ba2-c33d-4165-bab6-bc72c053b099",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load all session data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c208b917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ephys_object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>230503_r1354</th>\n",
       "      <td>&lt;pyscan.ephys.ephys object at 0x7f499072de20&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230504_r1354</th>\n",
       "      <td>&lt;pyscan.ephys.ephys object at 0x7f48c99efc10&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230505_r1354</th>\n",
       "      <td>&lt;pyscan.ephys.ephys object at 0x7f48cb663100&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230506_r1354</th>\n",
       "      <td>&lt;pyscan.ephys.ephys object at 0x7f48c9994ca0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230507_r1354</th>\n",
       "      <td>&lt;pyscan.ephys.ephys object at 0x7f48c99b9f40&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               ephys_object\n",
       "230503_r1354  <pyscan.ephys.ephys object at 0x7f499072de20>\n",
       "230504_r1354  <pyscan.ephys.ephys object at 0x7f48c99efc10>\n",
       "230505_r1354  <pyscan.ephys.ephys object at 0x7f48cb663100>\n",
       "230506_r1354  <pyscan.ephys.ephys object at 0x7f48c9994ca0>\n",
       "230507_r1354  <pyscan.ephys.ephys object at 0x7f48c99b9f40>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pickled data\n",
    "df_all_sessions = pd.read_pickle('/home/isabella/Documents/isabella/jake/ephys_analysis/processed_data/df_all_cells.pkl')\n",
    "\n",
    "# Load all session names and paths as dict\n",
    "session_dict = find_all_sessions(sheet_path = 'https://docs.google.com/spreadsheets/d/1_Xs5i-rHNTywV-WuQ8-TZliSjTxQCCqGWOD2AL_LIq0/edit#gid=0',\n",
    "                                 data_path = '/home/isabella/Documents/isabella/jake/recording_data',\n",
    "                                 sorting_suffix = 'sorting_ks2_custom')\n",
    "\n",
    "# # TESTING Drop all but a single row\n",
    "# session_dict = {k: session_dict[k] for k in list(session_dict)[10:11]}\n",
    "\n",
    "df_all_sessions = make_df_all_sessions(session_dict, recording_type = 'nexus' )\n",
    "\n",
    "\n",
    "    \n",
    "# # Drop rows with no included clusters\n",
    "# df_all_cells = df_all_cells.dropna()\n",
    "# print(f'{len(df_all_cells.index)} sessions retained')\n",
    "\n",
    "df_all_sessions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9385a8c",
   "metadata": {},
   "source": [
    "## Load theta phase and cycle for each trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78c3cc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded theta phase data for trial: 230503_r1354_raw_t-maze_1\n",
      "Loaded theta phase data for trial: 230504_r1354_raw_open-field_1\n",
      "Loaded theta phase data for trial: 230504_r1354_raw_open-field_2\n",
      "Loaded theta phase data for trial: 230504_r1354_raw_t-maze_1\n",
      "Loaded theta phase data for trial: 230505_r1354_raw_open-field_1\n",
      "Loaded theta phase data for trial: 230505_r1354_raw_t-maze_1\n",
      "Loaded theta phase data for trial: 230505_r1354_raw_open-field_2\n",
      "Loaded theta phase data for trial: 230505_r1354_raw_t-maze_2\n",
      "Loaded theta phase data for trial: 230506_r1354_raw_open-field_1\n",
      "Loaded theta phase data for trial: 230506_r1354_raw_t-maze_1\n",
      "Loaded theta phase data for trial: 230506_r1354_raw_open-field_2\n",
      "Loaded theta phase data for trial: 230506_r1354_raw_t-maze_2\n",
      "Loaded theta phase data for trial: 230507_r1354_raw_open-field_1\n",
      "Loaded theta phase data for trial: 230507_r1354_raw_t-maze_1\n",
      "Loaded theta phase data for trial: 230507_r1354_raw_open-field_2\n",
      "Loaded theta phase data for trial: 230508_r1354_raw_open-field_1\n",
      "Loaded theta phase data for trial: 230508_r1354_raw_t-maze_1\n",
      "Loaded theta phase data for trial: 230508_r1354_raw_open-field_2\n",
      "Loaded theta phase data for trial: 230508_r1354_raw_t-maze_2\n",
      "Loaded theta phase data for trial: 230509_r1354_raw_open-field_1\n",
      "Loaded theta phase data for trial: 230509_r1354_raw_t-maze_1\n",
      "Loaded theta phase data for trial: 230509_r1354_raw_open-field_2\n",
      "Loaded theta phase data for trial: 230509_r1354_raw_t-maze_2\n",
      "Loaded theta phase data for trial: 230510_r1354_raw_open-field_1\n",
      "Loaded theta phase data for trial: 230510_r1354_raw_t-maze_1\n",
      "Loaded theta phase data for trial: 230510_r1354_raw_open-field_2\n",
      "Loaded theta phase data for trial: 230607_r1364_raw_open-field_1\n",
      "Loaded theta phase data for trial: 230607_r1364_raw_open-field_2\n",
      "Loaded theta phase data for trial: 230607_r1364_raw_t-maze_1\n",
      "Loaded theta phase data for trial: 230607_r1364_raw_t-maze_2\n",
      "Loaded theta phase data for trial: 230608_r1364_raw_open-field_1\n",
      "Loaded theta phase data for trial: 230608_r1364_raw_t-maze_1\n",
      "Loaded theta phase data for trial: 230608_r1364_raw_open-field_2\n",
      "Loaded theta phase data for trial: 230609_r1364_raw_open-field_1\n",
      "Loaded theta phase data for trial: 230609_r1364_raw_t-maze_1\n",
      "Loaded theta phase data for trial: 230609_r1364_raw_open-field_2\n",
      "Loaded theta phase data for trial: 230609_r1364_raw_t-maze_2\n",
      "Loaded theta phase data for trial: 230610_r1364_raw_open-field_1\n",
      "Loaded theta phase data for trial: 230610_r1364_raw_t-maze_1\n",
      "Loaded theta phase data for trial: 230610_r1364_raw_open-field_2\n",
      "Loaded theta phase data for trial: 230610_r1364_raw_t-maze_2\n",
      "Loaded theta phase data for trial: 230611_r1364_raw_open-field_1\n",
      "Loaded theta phase data for trial: 230611_r1364_raw_t-maze_1\n",
      "Loaded theta phase data for trial: 230611_r1364_raw_open-field_2\n"
     ]
    }
   ],
   "source": [
    "from spelt.analysis.get_theta_frequencies import get_theta_frequencies\n",
    "from spelt.analysis.get_theta_phase import get_theta_phase\n",
    "\n",
    "lfp_sampling_rate = 1000\n",
    "# channels_to_load = [35, 58, 37, 56, 39, 55, 40, 57, 38, 54, 41, 53, 42] # From generate 5x12/16 probe script, corresponding to central shank @0um to -1200um\n",
    "channels_to_load = [35] # From generate 5x12/16 probe script, corresponding to central shank @0um\n",
    "\n",
    "# Loop through sessions\n",
    "for row, obj in enumerate(df_all_sessions.loc[:, 'ephys_object']):\n",
    "    \n",
    "    # Initalise object attribute to store theta phase data\n",
    "    obj.cycle_data = [{} for _ in range(len(obj.trial_list))]\n",
    "    \n",
    "    # Load theta phase info for all trials\n",
    "    for trial_iterator, trial in enumerate(obj.trial_list):\n",
    "\n",
    "        # Load LFP for trial from contact on central shank at 0um (channel 15 on the 5x12/16 Buz probe)\n",
    "        obj.load_lfp(trial_iterator,\n",
    "                        sampling_rate = lfp_sampling_rate, \n",
    "                        channels  = channels_to_load, \n",
    "                        reload_flag = True, ##CHANGE BACK IF NEEDED\n",
    "                        scale_to_uv = False)\n",
    "        \n",
    "        # Find peak theta frequencies for channel @ 0um and make dict of {channel: theta_freq}\n",
    "        theta_freqs = get_theta_frequencies(obj.lfp_data[trial_iterator]['data'], lfp_sampling_rate)\n",
    "        theta_freqs = dict(zip(channels_to_load, theta_freqs))\n",
    "\n",
    "        # Initialise theta phase array\n",
    "        theta_phase = [None] * len(channels_to_load)\n",
    "        cycle_numbers = [None] * len(channels_to_load)\n",
    "\n",
    "        # Loop through each included channel\n",
    "        for channel_iterator, channel in enumerate(channels_to_load):\n",
    "\n",
    "            # Get peak theta frequency\n",
    "            theta_freq = theta_freqs[channel]\n",
    "\n",
    "            # Get LFP data for channel\n",
    "            lfp_data_for_channel = obj.lfp_data[trial_iterator]['data'][:, channel_iterator]\n",
    "\n",
    "            # Calculate theta phase\n",
    "            theta_phase[channel_iterator], cycle_numbers[channel_iterator] = get_theta_phase(lfp_data_for_channel, lfp_sampling_rate, theta_freq, clip_value = 32000) #CLIP VALUE FOR AXONA ONLY\n",
    "\n",
    "\n",
    "        # Add theta phase data to object\n",
    "        obj.cycle_data[trial_iterator]['theta_phase'] = np.array(theta_phase).T\n",
    "        # Add cycle numbers data to object\n",
    "        obj.cycle_data[trial_iterator]['cycle_numbers'] = np.array(cycle_numbers).T\n",
    "        print(f'Loaded theta phase data for trial: {trial}')\n",
    "                        \n",
    "    df_all_sessions.at[list(session_dict.keys())[row], 'ephys_object'] = obj\n",
    "\n",
    "# Save df_all_sessions to pickle\n",
    "df_all_sessions.to_pickle('/home/isabella/Documents/isabella/jake/ephys_analysis/processed_data/df_all_sessions_theta_phase.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58800bb7",
   "metadata": {},
   "source": [
    "## For each t-maze trial - compute CSD by arm for each theta cycle, plot and save result to dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d7b1c5-f317-420a-8c6a-f1b7d79ce28b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Select times when animal is in choice or return arms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb20def8-6a2f-4f46-afc5-ab2e4bd44ae5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from spelt.analysis.position_analysis import assign_sectors\n",
    "\n",
    "# Load from pickle\n",
    "df_all_sessions = pd.read_pickle('/home/isabella/Documents/isabella/jake/ephys_analysis/processed_data/df_all_sessions_theta_phase.pkl')\n",
    "\n",
    "# Loop through sessions\n",
    "trials_loaded = 0\n",
    "for row, obj in enumerate(df_all_sessions.loc[:, 'ephys_object']):\n",
    "        \n",
    "    # Load position for t-maze trials\n",
    "    for trial_iterator, trial in enumerate(obj.trial_list):\n",
    "        if 't-maze' in trial:\n",
    "            obj.load_pos(trial_iterator, reload_flag = False)\n",
    "            trials_loaded +=1\n",
    "            \n",
    "            # Assign sectors to positions samples\n",
    "            sector_numbers = np.array(assign_sectors(obj.pos_data[trial_iterator]['xy_position'].T, pos_header = obj.pos_data[trial_iterator]['header']))\n",
    "            \n",
    "            # Define central and return arm position sectors\n",
    "            central_sectors = [6, 7]\n",
    "            return_sectors = [2, 3, 10, 11]\n",
    "            \n",
    "            # Find position samples where the animal is in each arm type\n",
    "            central_samples = np.where(np.isin(sector_numbers, central_sectors))[0]\n",
    "            return_samples = np.where(np.isin(sector_numbers, return_sectors))[0]\n",
    "            \n",
    "            # Get position sampling rate\n",
    "            pos_sample_rate = obj.pos_data[trial_iterator]['pos_sampling_rate']\n",
    "            \n",
    "            #Convert these samples into times (in s) through the trial (divide by sample rate), then add to obj\n",
    "            obj.pos_data[trial_iterator]['central_times'] = central_samples / pos_sample_rate\n",
    "            obj.pos_data[trial_iterator]['return_times'] = return_samples / pos_sample_rate            \n",
    "            \n",
    "            df_all_sessions.at[list(session_dict.keys())[row], 'ephys_object'] = obj\n",
    "            \n",
    "                      \n",
    "print(f'{trials_loaded} t-maze trials loaded')\n",
    "\n",
    "# Save df_all_sessions to pickle\n",
    "df_all_sessions.to_pickle('/home/isabella/Documents/isabella/jake/ephys_analysis/processed_data/df_all_sessions_theta_phase.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b615b9c",
   "metadata": {},
   "source": [
    "### Compute CSD and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e960048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spelt.analysis.get_traversal_data import get_traversal_cycles, get_data_for_traversals, drop_extreme_cycles\n",
    "from spelt.analysis.bz_csd import calculate_csd_df, mean_csd_theta_phase, plot_csd_theta_phase\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "channels_to_load = [35, 58, 37, 56, 39, 55, 40, 57, 38, 54, 41, 53, 42] # From generate 5x12/16 probe script, corresponding to central shank @0um to -1200um\n",
    "channel_depths = np.arange(len(channels_to_load)) * -100\n",
    "figure_dir = '/home/isabella/Documents/isabella/jake/ephys_analysis/figures'\n",
    "\n",
    "# Load from pickle\n",
    "df_all_sessions = pd.read_pickle('/home/isabella/Documents/isabella/jake/ephys_analysis/processed_data/df_all_sessions_theta_phase.pkl')\n",
    "\n",
    "# freq_band = [60, 100]\n",
    "freq_band = [4, 12]\n",
    "freq_band_name = 'Theta'\n",
    "\n",
    "# Create dataframes for output\n",
    "cycle_df = pd.DataFrame(columns=['Central Cycles', 'Return Cycles']).astype(object)\n",
    "central_mean_csd_df = pd.DataFrame()\n",
    "return_mean_csd_df = pd.DataFrame()\n",
    "    \n",
    "# Loop through sessions\n",
    "for obj in df_all_sessions.loc[:, 'ephys_object']:\n",
    "        \n",
    "    # Loop through t-maze trials\n",
    "    for trial_iterator, trial in ((i, t) for i, t in enumerate(obj.trial_list) if 't-maze' in t):\n",
    "        \n",
    "        # Set CSD save path\n",
    "        csd_path = f'{figure_dir}/P{obj.age}_{obj.date_short}_{obj.animal}/CSD'\n",
    "        # Check if the directory exists, if not, create it\n",
    "        if not os.path.exists(csd_path):\n",
    "            os.makedirs(csd_path)\n",
    "        \n",
    "        ## Get central and return arm times from object\n",
    "        central_times = obj.pos_data[trial_iterator]['central_times']\n",
    "        return_times = obj.pos_data[trial_iterator]['return_times']\n",
    "\n",
    "        ## Load relevant lfp data from object\n",
    "        cycle_numbers = obj.cycle_data[trial_iterator]['cycle_numbers']\n",
    "        theta_phase = obj.cycle_data[trial_iterator]['theta_phase']\n",
    "        lfp_timestamps = obj.lfp_data[trial_iterator]['timestamps']\n",
    "        lfp_sampling_rate = obj.lfp_data[trial_iterator]['sampling_rate']\n",
    "\n",
    "\n",
    "        ## Reload LFP data to include all relevant channels for CSD calculation. This will load 13 channels worth of LFP data \n",
    "        # This will also write over the calculated metrics stored above\n",
    "        obj.load_lfp(trial_iterator,\n",
    "         sampling_rate = lfp_sampling_rate, \n",
    "         channels  = channels_to_load, \n",
    "         reload_flag = True,\n",
    "         scale_to_uv = False,\n",
    "         bandpass_filter = freq_band)\n",
    "\n",
    "        lfp_data = obj.lfp_data[trial_iterator]['data']\n",
    "\n",
    "        ## Get speed data and align to LFP timestamps\n",
    "        speed_data = obj.pos_data[trial_iterator]['speed']\n",
    "        pos_sampling_rate = obj.pos_data[trial_iterator]['pos_sampling_rate']\n",
    "        num_data_points = len(speed_data)\n",
    "        # Original timestamps at 50 Hz\n",
    "        original_timestamps = np.linspace(0, num_data_points/pos_sampling_rate, num=num_data_points, endpoint=True)\n",
    "        # Create interpolation function\n",
    "        interpolation_function = interp1d(original_timestamps, speed_data, kind='linear')\n",
    "        # Interpolate to get new data at 1000 Hz\n",
    "        resampled_speed_data = interpolation_function(lfp_timestamps)\n",
    "\n",
    "        ## Calculate individual arm traversals and get identity of whole theta cycles within each traversal\n",
    "        central_cycles = get_traversal_cycles(central_times, cycle_numbers, lfp_timestamps, lfp_sampling_rate)\n",
    "        return_cycles = get_traversal_cycles(return_times, cycle_numbers, lfp_timestamps, lfp_sampling_rate)\n",
    "\n",
    "        ## Get lfp trace, theta phase, timestamps, speed, cycle index and traversal index for included individual theta cycles\n",
    "        central_cycle_df = get_data_for_traversals(central_cycles, cycle_numbers, lfp_data, resampled_speed_data, channels_to_load, theta_phase, lfp_timestamps)\n",
    "        return_cycle_df = get_data_for_traversals(return_cycles, cycle_numbers, lfp_data, resampled_speed_data, channels_to_load, theta_phase, lfp_timestamps)\n",
    "\n",
    "        # Drop cycles where any lfp data > |32000| (clip value for axona)\n",
    "        def filter_func(x):\n",
    "            # If any value in the group is greater than 32000, exclude the whole group\n",
    "            if (x.drop(\"Cycle Index\", axis=1).abs() > 32000).any(axis=None):\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "\n",
    "        central_cycle_df = central_cycle_df.T.groupby('Cycle Index').filter(filter_func)\n",
    "        return_cycle_df = return_cycle_df.T.groupby('Cycle Index').filter(filter_func)\n",
    "\n",
    "\n",
    "        ## Loop through each traversal in the dataframe and calculate CSD, add to dataframe\n",
    "        print(f\"Calculating Central CSD using {len(np.unique(central_cycle_df['Cycle Index']))} theta cycles\") \n",
    "        print(f\"Calculating Return CSD using {len(np.unique(return_cycle_df['Cycle Index']))} theta cycles\")\n",
    "        central_csd_df, central_csd_labels = calculate_csd_df(central_cycle_df.T)\n",
    "        return_csd_df, return_csd_labels = calculate_csd_df(return_cycle_df.T)\n",
    "\n",
    "\n",
    "        # Drop the first and last theta cycle for each traversal to remove calculation artefacts\n",
    "        central_csd_df = drop_extreme_cycles(central_csd_df)\n",
    "        return_cycle_df = drop_extreme_cycles(return_csd_df)\n",
    "\n",
    "        ## Filter dataframe for speed > 2.5 cm/s\n",
    "        central_csd_df = central_csd_df.loc[:, central_csd_df.loc['Speed'] > 2.5]\n",
    "        return_csd_df = return_csd_df.loc[:, return_csd_df.loc['Speed'] > 2.5]\n",
    "        \n",
    "        print(f'Calculated CSD for trial {trial}')\n",
    "\n",
    "        ## Compute mean CSD vs theta phase for each arm\n",
    "        central_csd_theta_phase = mean_csd_theta_phase(central_csd_df, central_csd_labels)\n",
    "        return_csd_theta_phase = mean_csd_theta_phase(return_csd_df, return_csd_labels)\n",
    "        #Plot\n",
    "        plot_csd_theta_phase(central_csd_theta_phase, \n",
    "                             title = f'Central Arm - {freq_band_name}', save_path = f'{csd_path}/{trial}_CSD_Theta_Phase_Central_{freq_band_name}.png')\n",
    "        plot_csd_theta_phase(return_csd_theta_phase, \n",
    "                             title = f'Return Arm - {freq_band_name}', save_path = f'{csd_path}/{trial}_CSD_Theta_Phase_Return_{freq_band_name}.png')\n",
    "        \n",
    "        ## Calculate the difference and plot\n",
    "        subtracted_csd_theta_phase = central_csd_theta_phase - return_csd_theta_phase\n",
    "        plot_csd_theta_phase(subtracted_csd_theta_phase, title = f'Subtracted - {freq_band_name}')\n",
    "        \n",
    "        ## Mean csd for each channel and plot\n",
    "        mean_central_csd = central_csd_df.mean(axis = 1)[central_csd_labels]\n",
    "        mean_return_csd = return_csd_df.mean(axis = 1)[return_csd_labels]\n",
    "        \n",
    "        plt.plot(mean_central_csd.values, mean_central_csd.index, label = 'Centre', c = 'orange')\n",
    "        plt.plot(mean_return_csd.values, mean_return_csd.index, label = 'Return', c = 'blue')\n",
    "        plt.legend()\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.yticks(mean_central_csd.index.to_list(), channel_depths)\n",
    "        plt.ylabel('Channel Depth (μm)')\n",
    "        plt.axvline(x=0, color='grey', linestyle='--', dashes=[5, 5])\n",
    "        plt.savefig(f'{csd_path}/{trial}_mean_CSD_{freq_band_name}.png')\n",
    "        plt.title(f'Mean CSD - {freq_band_name}')\n",
    "        plt.show()\n",
    "    \n",
    "        ## Add to dataframe for all sessions\n",
    "        mean_central_csd.columns = [trial]\n",
    "        central_mean_csd_df = pd.concat([central_mean_csd_df, mean_central_csd], axis=1)\n",
    "        \n",
    "        mean_return_csd.columns = [trial]\n",
    "        return_mean_csd_df = pd.concat([return_mean_csd_df, mean_return_csd], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d94936",
   "metadata": {},
   "source": [
    "### Plot mean t-maze CSD across all sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9ebb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(central_mean_csd_df.mean(axis=1).values, central_mean_csd_df.mean(axis=1).index, c = 'orange', label = 'central')\n",
    "plt.plot(return_mean_csd_df.mean(axis=1).values, return_mean_csd_df.mean(axis=1).index, c = 'blue', label = 'return')\n",
    "# Plot standard error\n",
    "plt.fill_betweenx(central_mean_csd_df.mean(axis=1).index, central_mean_csd_df.mean(axis=1).values - central_mean_csd_df.sem(axis=1).values, central_mean_csd_df.mean(axis=1).values + central_mean_csd_df.sem(axis=1).values, alpha=0.2, color='orange')\n",
    "plt.fill_betweenx(return_mean_csd_df.mean(axis=1).index, return_mean_csd_df.mean(axis=1).values - return_mean_csd_df.sem(axis=1).values, return_mean_csd_df.mean(axis=1).values + return_mean_csd_df.sem(axis=1).values, alpha=0.2, color='blue')\n",
    "\n",
    "plt.legend()\n",
    "plt.gca().invert_yaxis()\n",
    "plt.yticks(return_mean_csd_df.mean(axis=1).index.to_list(), channel_depths)\n",
    "plt.axvline(x=0, color='grey', linestyle='--', dashes=[5, 5])\n",
    "plt.ylabel('Channel Depth (μm)')\n",
    "plt.xlabel('CSD')\n",
    "plt.title(f'Mean CSD across all sessions - {freq_band_name}')\n",
    "plt.savefig(f'{csd_path}/all_trials_mean_CSD_{freq_band_name}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534a0982",
   "metadata": {},
   "source": [
    "## Plot theta phase CSD for all open field trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aed38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spelt.analysis.get_traversal_data import drop_extreme_cycles\n",
    "from spelt.analysis.bz_csd import calculate_csd_df, mean_csd_theta_phase, plot_csd_theta_phase\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "channels_to_load = [35, 58, 37, 56, 39, 55, 40, 57, 38, 54, 41, 53, 42] # From generate 5x12/16 probe script, corresponding to central shank @0um to -1200um\n",
    "channel_depths = np.arange(len(channels_to_load)) * -100\n",
    "figure_dir = '/home/isabella/Documents/isabella/jake/ephys_analysis/figures'\n",
    "\n",
    "# Load from pickle\n",
    "df_all_sessions = pd.read_pickle('/home/isabella/Documents/isabella/jake/ephys_analysis/processed_data/df_all_sessions_theta_phase.pkl')\n",
    "\n",
    "# freq_band = [60, 80]\n",
    "freq_band = [4, 12]\n",
    "freq_band_name = 'Theta'\n",
    "\n",
    "# Create dataframes for output\n",
    "cycle_df = pd.DataFrame(columns=['Theta Cycles']).astype(object)\n",
    "mean_csd_df = pd.DataFrame()\n",
    "\n",
    "csds_thata_phase = {}\n",
    "    \n",
    "# Loop through sessions\n",
    "for obj in df_all_sessions.loc[:, 'ephys_object']:\n",
    "        \n",
    "    # Loop through open field trials\n",
    "    for trial_iterator, trial in ((i, t) for i, t in enumerate(obj.trial_list) if 'open-field' in t):\n",
    "        \n",
    "        # Set CSD save path\n",
    "        csd_path = f'{figure_dir}/P{obj.age}_{obj.date_short}_{obj.animal}/CSD'\n",
    "        # Check if the directory exists, if not, create it\n",
    "        if not os.path.exists(csd_path):\n",
    "            os.makedirs(csd_path)\n",
    "\n",
    "        ## Load relevant lfp data from object\n",
    "        cycle_numbers = obj.cycle_data[trial_iterator]['cycle_numbers']\n",
    "        theta_phase = obj.cycle_data[trial_iterator]['theta_phase']\n",
    "        \n",
    "        lfp_timestamps = obj.lfp_data[trial_iterator]['timestamps']\n",
    "        lfp_sampling_rate = obj.lfp_data[trial_iterator]['sampling_rate']\n",
    "\n",
    "\n",
    "        ## Reload LFP data to include all relevant channels for CSD calculation. This will load 13 channels worth of LFP data, and filter to the specified frequency band\n",
    "        # This will also write over the calculated metrics stored above\n",
    "        obj.load_lfp(trial_iterator,\n",
    "         sampling_rate = lfp_sampling_rate, \n",
    "         channels  = channels_to_load, \n",
    "         reload_flag = True,\n",
    "         scale_to_uv = False,\n",
    "         bandpass_filter = freq_band)\n",
    "\n",
    "        lfp_data = obj.lfp_data[trial_iterator]['data']\n",
    "\n",
    "        ## Get speed data and align to LFP timestamps\n",
    "        obj.load_pos(trial_iterator, reload_flag = False, output_flag = False)\n",
    "        speed_data = obj.pos_data[trial_iterator]['speed']\n",
    "        pos_sampling_rate = obj.pos_data[trial_iterator]['pos_sampling_rate']\n",
    "        num_data_points = len(speed_data)\n",
    "\n",
    "        # Original timestamps at 50 Hz\n",
    "        original_timestamps = np.linspace(0, num_data_points/pos_sampling_rate, num=num_data_points, endpoint=True)\n",
    "        # Create interpolation function\n",
    "        interpolation_function = interp1d(original_timestamps, speed_data, kind='linear')\n",
    "        # Interpolate to get new data at 1000 Hz\n",
    "        resampled_speed_data = interpolation_function(lfp_timestamps)\n",
    "\n",
    "        ## Make dataframe of all lfp data, speed and cycle index\n",
    "        cycle_df = pd.DataFrame(lfp_data, columns = channels_to_load)\n",
    "        cycle_df['Cycle Index'] = cycle_numbers\n",
    "        cycle_df['Cycle Theta Phase'] = theta_phase\n",
    "        cycle_df['Speed'] = resampled_speed_data\n",
    "\n",
    "        # Add traversal as zeroes (consider all session a single traversal for open field)\n",
    "        cycle_df['Traversal Index'] = np.zeros(len(cycle_df.index))\n",
    "\n",
    "        # Drop cycles where any lfp data > |32000| (clip value for axona)\n",
    "        def filter_func(x):\n",
    "            # If any value in the group is greater than 32000, exclude the whole group\n",
    "            if (x.drop('Cycle Index', axis=1).abs() > 32000).any(axis=None):\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "\n",
    "        cycle_df = cycle_df.groupby('Cycle Index').filter(filter_func)\n",
    "        print(f'Dropped {round((len(lfp_data) - len(cycle_df.index)) / len(lfp_data) * 100, 2)} % of samples due to clipping in cycle')\n",
    "\n",
    "        # Drop rows with NaN cycle indices\n",
    "        cycle_df = cycle_df.dropna(subset=['Cycle Index'])\n",
    "\n",
    "        ## Calculate CSD\n",
    "        print(f\"Calculating CSD using {len(np.unique(cycle_df['Cycle Index']))} theta cycles\")  \n",
    "        csd_df, csd_labels = calculate_csd_df(cycle_df.T)\n",
    "\n",
    "        # Drop the first and last theta cycle for each traversal to remove calculation artefacts\n",
    "        csd_df = drop_extreme_cycles(csd_df)\n",
    "\n",
    "        ## Filter dataframe for speed > 2.5 cm/s\n",
    "        csd_df = csd_df.loc[:, csd_df.loc['Speed'] > 2.5]\n",
    "\n",
    "        print(f'Calculated CSD for trial {trial}')\n",
    "\n",
    "        ## Compute mean CSD vs theta phase\n",
    "        csd_theta_phase = mean_csd_theta_phase(csd_df, csd_labels)\n",
    "        csds_thata_phase[trial] = csd_theta_phase # add to dict\n",
    "\n",
    "        #Plot\n",
    "        plot_csd_theta_phase(csd_theta_phase, \n",
    "                             title = f'Open Field - {freq_band_name}', save_path = f'{csd_path}/{trial}_CSD_Theta_Phase_Open-Field_{freq_band_name}.png')\n",
    "        \n",
    "        ## Mean csd for each channel and plot\n",
    "        mean_csd = csd_df.mean(axis = 1)[csd_labels]\n",
    "        \n",
    "        plt.plot(mean_csd.values, mean_csd.index, label = 'Open Field', c = 'orange')\n",
    "        plt.legend()\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.yticks(mean_csd.index.to_list(), channel_depths)\n",
    "        plt.ylabel('Channel Depth (μm)')\n",
    "        plt.axvline(x=0, color='grey', linestyle='--', dashes=[5, 5])\n",
    "        plt.savefig(f'{csd_path}/{trial}_mean_CSD_{freq_band_name}.png')\n",
    "        plt.title(f'Mean CSD - {freq_band_name}')\n",
    "        plt.show()\n",
    "    \n",
    "        ## Add to dataframe for all sessions\n",
    "        mean_csd.columns = [trial]\n",
    "        mean_csd_df = pd.concat([mean_csd_df, mean_csd], axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a945910",
   "metadata": {},
   "source": [
    "### Plot mean open field CSD across all sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc58c7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mean_csd_df.mean(axis=1).values, mean_csd_df.mean(axis=1).index, c = 'orange', label = 'open-field')\n",
    "# Plot standard error\n",
    "plt.fill_betweenx(mean_csd_df.mean(axis=1).index, mean_csd_df.mean(axis=1).values - mean_csd_df.sem(axis=1).values, mean_csd_df.mean(axis=1).values + mean_csd_df.sem(axis=1).values, alpha=0.2, color='orange')\n",
    "\n",
    "plt.legend()\n",
    "plt.gca().invert_yaxis()\n",
    "plt.yticks(mean_csd_df.mean(axis=1).index.to_list(), channel_depths)\n",
    "plt.axvline(x=0, color='grey', linestyle='--', dashes=[5, 5])\n",
    "plt.ylabel('Channel Depth (μm)')\n",
    "plt.xlabel('CSD')\n",
    "plt.title(f'Mean CSD across all sessions - {freq_band_name}')\n",
    "plt.savefig(f'{csd_path}/all_trials_mean_CSD_{freq_band_name}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e8ded2-8d55-4ad7-8b3f-21ae53756d91",
   "metadata": {
    "tags": []
   },
   "source": [
    "## For each t-maze trial - plot theta phase against frequency power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5bf812-e628-47fc-9d91-1e1ee40b4662",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from spelt.analysis.get_traversal_data import get_traversal_cycles, get_data_for_traversals, drop_extreme_cycles\n",
    "from spelt.analysis.frequency_power import calculate_morlet_df, plot_wavelet_power_spectrum_theta\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# channels_to_load = [35, 58, 37, 56, 39, 55, 40, 57, 38, 54, 41, 53, 42] # From generate 5x12/16 probe script, corresponding to central shank @0um to -1200um\n",
    "# channels_to_load = [35]\n",
    "figure_dir = '/home/isabella/Documents/isabella/jake/ephys_analysis/figures'\n",
    "\n",
    "f_min = 30\n",
    "f_max = 140\n",
    "f_bins = 100\n",
    "\n",
    "# Create dataframes for output\n",
    "cycle_df = pd.DataFrame(columns=['Central Cycles', 'Return Cycles']).astype(object)\n",
    "# central_mean_csd_df = pd.DataFrame()\n",
    "# return_mean_csd_df = pd.DataFrame()\n",
    "    \n",
    "# Loop through sessions\n",
    "for obj in df_all_sessions.loc[:, 'ephys_object']:\n",
    "        \n",
    "    # Loop through t-maze trials\n",
    "    for trial_iterator, trial in ((i, t) for i, t in enumerate(obj.trial_list) if 't-maze' in t):\n",
    "        \n",
    "        # Set spectrogram save path\n",
    "        spec_path = f'{figure_dir}/P{obj.age}_{obj.date_short}_{obj.animal}/spectrograms'\n",
    "        # Check if the directory exists, if not, create it\n",
    "        if not os.path.exists(spec_path):\n",
    "            os.makedirs(spec_path)\n",
    "        \n",
    "        ## Get central and return arm times from object\n",
    "        central_times = obj.pos_data[trial_iterator]['central_times']\n",
    "        return_times = obj.pos_data[trial_iterator]['return_times']\n",
    "\n",
    "        ## Load relevant lfp data from object\n",
    "        cycle_numbers = obj.cycle_data[trial_iterator]['cycle_numbers']\n",
    "        theta_phase = obj.cycle_data[trial_iterator]['theta_phase']\n",
    "        lfp_timestamps = obj.lfp_data[trial_iterator]['timestamps']\n",
    "        lfp_sampling_rate = obj.lfp_data[trial_iterator]['sampling_rate']\n",
    "\n",
    "\n",
    "        # ## Reload LFP data to include all relevant channels for wavelet calculation. This will load 13 channels worth of LFP data \n",
    "        # # This will also write over the calculated metrics stored above\n",
    "        # obj.load_lfp(trial_iterator,\n",
    "        #  sampling_rate = lfp_sampling_rate, \n",
    "        #  channels  = channels_to_load, \n",
    "        #  reload_flag = False, ##CAREFUL - CHANGE IF NEEDED\n",
    "        #  scale_to_uv = True,\n",
    "        #  bandpass_filter = freq_band)\n",
    "\n",
    "        lfp_data = obj.lfp_data[trial_iterator]['data']\n",
    "\n",
    "        ## Get speed data and align to LFP timestamps\n",
    "        speed_data = obj.pos_data[trial_iterator]['speed']\n",
    "        pos_sampling_rate = obj.pos_data[trial_iterator]['pos_sampling_rate']\n",
    "        num_data_points = len(speed_data)\n",
    "        # Original timestamps at 50 Hz\n",
    "        original_timestamps = np.linspace(0, num_data_points/pos_sampling_rate, num=num_data_points, endpoint=True)\n",
    "        # Create interpolation function\n",
    "        interpolation_function = interp1d(original_timestamps, speed_data, kind='linear')\n",
    "        # Interpolate to get new data at 1000 Hz\n",
    "        resampled_speed_data = interpolation_function(lfp_timestamps)\n",
    "\n",
    "        ## Calculate individual arm traversals and get identity of whole theta cycles within each traversal\n",
    "        central_cycles = get_traversal_cycles(central_times, cycle_numbers, lfp_timestamps, lfp_sampling_rate)\n",
    "        return_cycles = get_traversal_cycles(return_times, cycle_numbers, lfp_timestamps, lfp_sampling_rate)\n",
    "\n",
    "        ## Get lfp trace, theta phase, timestamps, speed, cycle index and traversal index for included individual theta cycles\n",
    "        central_cycle_df = get_data_for_traversals(central_cycles, cycle_numbers, lfp_data, resampled_speed_data, channels_to_load, theta_phase, lfp_timestamps)\n",
    "        return_cycle_df = get_data_for_traversals(return_cycles, cycle_numbers, lfp_data, resampled_speed_data, channels_to_load, theta_phase, lfp_timestamps)\n",
    "\n",
    "        ## Loop through each traversal in the dataframe and calculate frequency power, add to dataframe\n",
    "        # Perform the wavelet transform for each included channel and add to dict\n",
    "        morlet_dict = {}\n",
    "        for channel in channels_to_load:\n",
    "            central_morlet_df = calculate_morlet_df(arm_cycle_df = central_cycle_df,\n",
    "                                            channel = channel,\n",
    "                                            lfp_sampling_rate = lfp_sampling_rate,\n",
    "                                            f_min = f_min,\n",
    "                                            f_max = f_max,\n",
    "                                            f_bins = f_bins)\n",
    "            \n",
    "            return_morlet_df = calculate_morlet_df(arm_cycle_df = central_cycle_df,\n",
    "                                            channel = channel,\n",
    "                                            lfp_sampling_rate = lfp_sampling_rate,\n",
    "                                            f_min = f_min,\n",
    "                                            f_max = f_max,\n",
    "                                            f_bins = f_bins)\n",
    "            \n",
    "            # Drop the first and last theta cycle for each traversal to remove calculation artefacts\n",
    "            central_morlet_df = drop_extreme_cycles(central_morlet_df)\n",
    "            return_morlet_df = drop_extreme_cycles(return_morlet_df)\n",
    "            \n",
    "            ## Filter dataframe for speed > 2.5 cm/s\n",
    "            central_morlet_df = central_morlet_df.loc[:, central_morlet_df.loc['Speed'] > 2.5]\n",
    "            return_morlet_df = return_morlet_df.loc[:, return_morlet_df.loc['Speed'] > 2.5]\n",
    "            \n",
    "            ## Plot spectrogram for channel\n",
    "            plot_wavelet_power_spectrum_theta(wavelet_coeffs = central_morlet_df.drop(['Traversal Index', 'Cycle Index', 'Cycle Theta Phase', 'Speed']).T.values,\n",
    "                            theta_phase = central_morlet_df.loc(axis = 0)['Cycle Theta Phase'].to_numpy(),\n",
    "                            n_theta_bins = 100, \n",
    "                            frequencies = central_morlet_df.index.drop(['Traversal Index', 'Cycle Index', 'Cycle Theta Phase', 'Speed']).to_list(),\n",
    "                            arm = 'Central',\n",
    "                            save_dir = f'{spec_path}/{trial}_morlet_spectrogram_Central.png')\n",
    "            \n",
    "            plot_wavelet_power_spectrum_theta(wavelet_coeffs = return_morlet_df.drop(['Traversal Index', 'Cycle Index', 'Cycle Theta Phase', 'Speed']).T.values,\n",
    "                            theta_phase = return_morlet_df.loc(axis = 0)['Cycle Theta Phase'].to_numpy(),\n",
    "                            n_theta_bins = 100, \n",
    "                            frequencies = return_morlet_df.index.drop(['Traversal Index', 'Cycle Index', 'Cycle Theta Phase', 'Speed']).to_list(),\n",
    "                            arm = 'Return',\n",
    "                            save_dir = f'{spec_path}/{trial}_morlet_spectrogram_Return.png')\n",
    "            \n",
    "            \n",
    "            ## Add calculated wavelet coefficients to dict\n",
    "            \n",
    "            \n",
    "        print(f'Calculated complex morlet wavelet transform for trial {trial}')\n",
    "\n",
    "#         ## Add to dataframe for all sessions\n",
    "#         mean_central_csd.columns = [trial]\n",
    "#         central_mean_csd_df = pd.concat([central_mean_csd_df, mean_central_csd], axis=1)\n",
    "        \n",
    "#         mean_return_csd.columns = [trial]\n",
    "#         return_mean_csd_df = pd.concat([return_mean_csd_df, mean_return_csd], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2659a142-c5f6-4ab1-92fd-a56c0a7761b7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# UNUSED CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fcd90b-ee24-4a72-abe0-fd36c320fa21",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plot theta phase against frequency power for a single trial segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0960e703-9334-4127-92c4-cea8000eec0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import morlet\n",
    "\n",
    "def complex_morlet_wavelet_transform(signal, frequencies, fs):\n",
    "    \"\"\"\n",
    "    Apply the complex Morlet wavelet transform to a signal for a range of frequencies.\n",
    "\n",
    "    :param signal: The input signal (time series)\n",
    "    :param frequencies: Array of frequencies for which to compute the transform\n",
    "    :param fs: Sampling frequency of the input signal\n",
    "    :return: An array of wavelet coefficients, time x frequencies\n",
    "    \"\"\"\n",
    "    wavelet_coeffs = np.zeros((len(signal), len(frequencies)), dtype=complex)\n",
    "    \n",
    "    # Perform wavelet transform for each frequency\n",
    "    for i, freq in enumerate(frequencies):\n",
    "        # Calculate the wavelet for given frequency and sampling frequency\n",
    "        wavelet = morlet(M=len(signal), w=5, s=freq / fs)\n",
    "        # Convolve signal with the wavelet\n",
    "        wavelet_coeffs[:, i] = np.convolve(signal, wavelet, mode='same')\n",
    "    \n",
    "    return wavelet_coeffs\n",
    "\n",
    "def plot_wavelet_power_spectrum(wavelet_coeffs, times, frequencies):\n",
    "    \"\"\"\n",
    "    Plot a time-resolved power spectrum from the wavelet coefficients.\n",
    "\n",
    "    :param wavelet_coeffs: Wavelet coefficients as returned by complex_morlet_wavelet_transform\n",
    "    :param times: Array of time points corresponding to the signal\n",
    "    :param frequencies: Array of frequencies used in the wavelet transform\n",
    "    \"\"\"\n",
    "    power_spectrum = np.abs(wavelet_coeffs) ** 2\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.pcolormesh(times, frequencies, power_spectrum.T, cmap='jet')\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.colorbar(label='Power')\n",
    "    plt.title('Time-Resolved Power Spectrum')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "# Define the frequency range for the analysis\n",
    "frequencies = np.linspace(1, 150, 100)  # (min_f, max_f, n_bins)\n",
    "t_min = 50000\n",
    "t_max = 100000\n",
    "lfp_data = obj.lfp_data[1]['data'][t_min:t_max]\n",
    "theta_phase = obj.lfp_data[1]['theta_phase'][t_min:t_max]\n",
    "\n",
    "# Perform the wavelet transform\n",
    "wavelet_coeffs = complex_morlet_wavelet_transform(lfp_data[:,0], frequencies, lfp_sampling_rate)\n",
    "\n",
    "n_bins = 50  # Number of bins for theta phase\n",
    "bin_edges = np.linspace(0, 2 * np.pi, n_bins + 1)\n",
    "power_spectra = np.zeros((len(frequencies), n_bins))\n",
    "\n",
    "for i in range(n_bins):\n",
    "    # Find indices for the current theta phase bin\n",
    "    indices = np.where((theta_phase >= bin_edges[i]) & (theta_phase < bin_edges[i + 1]))[0]\n",
    "\n",
    "    # Extract the wavelet coefficients for these indices\n",
    "    selected_coeffs = wavelet_coeffs[indices, :]\n",
    "\n",
    "    # Calculate the average power spectrum for this phase bin\n",
    "    power_spectra[:, i] = np.mean(np.abs(selected_coeffs) ** 2, axis=0)\n",
    "    \n",
    "# Smooth data across phase bins\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "# Apply this to each frequency bin\n",
    "sigma = 2  # Standard deviation for Gaussian kernel\n",
    "smoothed_power_spectra = np.array([gaussian_filter1d(power_spectra[i, :], sigma) for i in range(power_spectra.shape[0])])\n",
    "\n",
    "\n",
    "# Plotting\n",
    "theta_bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.pcolormesh(theta_bin_centers, frequencies, smoothed_power_spectra, cmap='jet')\n",
    "plt.xlabel('Theta Phase [radians]')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.colorbar(label='Power')\n",
    "plt.title('Theta Phase vs Frequency Power Spectrum')\n",
    "\n",
    "# Adjust the x-axis to show multiples of pi\n",
    "x_ticks = np.linspace(0, 2 * np.pi, 5)  # 0, pi/2, pi, 3pi/2, 2pi\n",
    "x_labels = ['0', r'$\\frac{\\pi}{2}$', r'$\\pi$', r'$\\frac{3\\pi}{2}$', r'$2\\pi$']\n",
    "plt.xticks(x_ticks, x_labels)\n",
    "\n",
    "# Overlay a theta cycle\n",
    "theta_cycle = np.cos(np.linspace(0, 2 * np.pi, 100))\n",
    "theta_phase_values = np.linspace(0, 2 * np.pi, 100)\n",
    "offset = np.median(frequencies)  # Adjust as per your plot\n",
    "theta_cycle_normalized = theta_cycle * np.ptp(frequencies)/4 + offset\n",
    "plt.plot(theta_phase_values, theta_cycle_normalized, color='white', linestyle='--', linewidth=2)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# # Plot the power spectrum\n",
    "# plot_wavelet_power_spectrum(wavelet_coeffs, obj.lfp_data[1]['timestamps'][t_min:t_max], frequencies)\n",
    "\n",
    "# plt.plot(obj.lfp_data[1]['timestamps'][t_min:t_max], (filtered_lfp[t_min:t_max]/300)+50, c = 'w')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
